{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark\n",
    "!pip3 install pyspark\n",
    "!pip install findspark\n",
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"nullValue\",\"NA\") \\\n",
    ".option(\"inferSchema\", \"true\").load(\"2007.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Partitions:\", df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar columnes\n",
    "df2 = df.drop(\"Flightfrom pyspark.sql.functions import exprNum\",\"TailNum\",\"UniqueCarrier\")\n",
    "#New frame with columns\n",
    "df2 = df.select(\"Origin\", \"Dest\", \"ArrDelay\", \"DepDelay\")\n",
    "df2.show()\n",
    "#Eliminar files on hi ha NA\n",
    "df3 = df2.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "##Suma, expr we can do expressions\n",
    "df4 = df3.withColumn(\"SumDelay\", expr(\"ArrDelay + DepDelay\"))\n",
    "#Action, no transformation\n",
    "df4.select(\"DepDelay\", \"ArrDelay\", \"SumDelay\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, min\n",
    "#es recorre tot el df\n",
    "df4.select(max(\"SumDelay\"),min(\"SumDelay\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "df4.select(max(\"SumDelay\"),min(\"SumDelay\"),avg(\"SumDelay\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporal save in cache or ram\n",
    "df4.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.where(\"SumDelay < 0\")\n",
    "df5.show() #accio, nomes mostra els primer elements\n",
    "df3.count()\n",
    "df5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.where(\"SumDelay < 0\").where(\"Origin == ’JFK’\")\n",
    "df5.show()\n",
    "df5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L’altre funció de filtratge disponible es diu filter. És molt similar a la funció where, amb l’a-\n",
    "#vantatge que es poden fer servir varibles de Python per establir els criteris sobre les condicions de\n",
    "#filtratge.\n",
    "from pyspark.sql.functions import col\n",
    "i = 0\n",
    "city = \"JFK\"\n",
    "df5 = df4.filter(col(\"SumDelay\") < i).filter(col(\"Origin\") == city)\n",
    "df5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercici\n",
    "from pyspark.sql.functions import sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc\n",
    "df5 = df4.sort(asc(\"SumDelay\"))\n",
    "df5.show()\n",
    "df5 = df4.sort(desc(\"SumDelay\")).limit(5)\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNIQUE Elements\n",
    "df5 = df4.select(\"Origin\").distinct()\n",
    "df5.count("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercici\n",
    "#Quantes destinacions diferents hi ha? A més, què és el que fa la següent operació?\n",
    "df4.select(\"Origin\",\"Dest\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dades = df4.limit(5).collect()\n",
    "dades\n",
    "dades[0]\n",
    "dades[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escriure a disc\n",
    "df4.rdd.getNumPartitions()\n",
    "#Per defecte, si ara escrivíssim les dades a disc, es crearien tants fitxers com particions hi ha\n",
    "df4_one = df4.coalesce(1)\n",
    "df4_one.rdd.getNumPartitions()\n",
    "df4_one = spark.write.format(\"csv\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".save(\"df4_one.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exercici\n",
    "\"\"\"És interessant que feu un experiment: abans hem ordenat els elements de df4 pel valor de SumDelay.\n",
    "Intenteu ordenar ara els valors de df4_one. Hi haurà alguna diferència en l’eficiència de l’ordenació?\n",
    "Feu servir alguna eina gràfica que us mostri el consum de CPU per veure-ho. Per a què és útil tenir\n",
    "les dades dividides en particions?\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
