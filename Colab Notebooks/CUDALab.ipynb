{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDALab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5bx2JSyCHfCq","colab_type":"text"},"source":["# Programaciò paral·lela\n","## Pràctica 2: Color conversion in CUDA\n","\n","Following the previous laboratory based on OpenMP, now we are going to work on the same simple algorithm, in CUDA.\n","\n","The goal of this lab is to learn the basics of CUDA kernels, and CUDA Host code.\n","\n","This new ipython notebook format, will make things easyer since explanation and code will coexist in the same document, and it will be very clear what you need to do.\n","\n","Additionally, having the Colab platform available with NVIDIA GPU's makes it simpler than ever. You can learn CUDA from any system, Mac, Windows, Linux, and any hardware, Intel, AMD, NVIDIA, and possibliy even ARM on tablets. You only need a web browser compatible with Colab.\n","\n","## Structure of the Lab (Pràctica)\n","You already know the algorithm from the previous lab, but you may not be familiar with this environment.\n","\n","First we will try to understand a bit this environment, and then we will explain section by section what you have to do. There are 6 sections.\n","\n","You will have to complete code in the 6 sections, and perform experiments and comment the results in a separated report. Use tables and figures that support both the results you collected and the arguments you make to justify the results.\n","\n","## The collab environment for CUDA\n","\n","First of all, you should know that we are executing an iPython notebook in a Google Colab session. The notebook is preconfigured with the type of execution environment we need, a GPU execution environment. But the files we generate, and the pluggins we install or enable, reside on the Google Colab session. All this will be removed when we exit the session either manually or implicitly by closing the broser.\n","\n","In order to have a GPU available when creating a new notebook, you only have to select the execution environment.\n","In Spanish, go to \"Entorno de ejecución->Cambiar tipo de entorno de ejecución\" and then select GPU.\n","\n","But as we already mentioned, this notebook is already configured, so you don't need to do it again.\n","\n","Now, the first thing we will see is that we have the nvcc compiler. We can call many bash commands with ! as the first character, in a code block. Next you will find a code block with a call to nvcc (the nvidia CUDA compiler) with a flag that asks for the compiler version.\n","\n","Click on the block and then a play button will appear on the left. Click on the play button. \n"]},{"cell_type":"code","metadata":{"id":"tNXYi-1xD-Zs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593441385006,"user_tz":-120,"elapsed":8863,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"a9613265-e44a-43c9-b6f0-a2c7d4280f31"},"source":["!rm dades.txt # Netejem el fitxer on guardarem les dades\n","!nvcc --version"],"execution_count":1,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'dades.txt': No such file or directory\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2019 NVIDIA Corporation\n","Built on Sun_Jul_28_19:07:16_PDT_2019\n","Cuda compilation tools, release 10.1, V10.1.243\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A4rhjdqSImo2","colab_type":"text"},"source":["You can also execute it by placing the cursor inside the code block and pressing Shift+Enter\n","\n","Next you need to install a pluggin, that does not come with the notebook. In the following code block you have the code line to be executed. You will have to execute this code every time you open the notebook."]},{"cell_type":"code","metadata":{"id":"2l1NOZW5ET_p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593441392049,"user_tz":-120,"elapsed":15876,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"ecde036e-4229-4777-c270-a397f73dec94"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc_plugin"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-2dkhl5cs\n","  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-2dkhl5cs\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=16dd8870804b64dc28798cbab563f012e22f615f404f1942c7d925ba6092e71e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-1v6geltt/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uuMz7OOYJVfk","colab_type":"text"},"source":["Now, you can compile and execute CUDA code, just by puting the same code you would put ina .cu file, just by adding %%cu as the first line.\n","\n","Next, you have a code example. Try it! Read the comments to help you understand it. It will be very useful for the tasks you have to do."]},{"cell_type":"code","metadata":{"id":"x03T7kcmEgu4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1593441394527,"user_tz":-120,"elapsed":18311,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"0cd17c7f-2980-4391-f4fa-0cccb34ee257"},"source":["%%cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","// Function to print the cuda errors\n","void cuCheck(cudaError_t err) {\n","    if(err!=cudaSuccess) {\n","          printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n","    }\n","}\n","\n","// This macros help with capturing the possible cuda errors and printing\n","// the error name to help the developer.\n","// Kernels are always asynchronous with respect to the Host, so they don't return\n","// any value. Then to see if any error happened, you should call cudaGetLastError\n","// and pass the result to cuCheck()\n","// Use the macros instead, to make it simpler.\n","#define CU_CHECK(a) cuCheck(a)\n","#define CU_CHECK_LAST_ERROR cuCheck(cudaGetLastError())\n","\n","// Device code or Kernel\n","__global__ void add(int a, int b, int* __restrict d_c) {\n","    *d_c = a * b;\n","}\n","\n","// Host code\n","int main() {\n","    \n","    // Host variables a & b\n","    int a = 3, b = 5, h_c = 0;\n","\n","    // Host variable that will store a Device pointer wich we can later on \n","    // download to the Host.\n","    // As this variable will contain pointers that are only valid in\n","    // the Device (the GPU) it will be invalid to access them from\n","    // Host code. We only can use them in the right cuda API calls\n","    // or inside a cuda Kernel.\n","    // So in this part of the code you won't be able to do d_c[0], for instance\n","    int *d_c;\n","\n","    // Size of the data contained in variables a, b and c.\n","    int dataSize = sizeof(int);\n","\n","    // Reserve Device memory using the cuda API\n","    // cudaMalloc will place a Device pointer inside d_c.\n","    CU_CHECK(\n","        cudaMalloc((void **)&d_c, dataSize)\n","    );\n","\n","    // Launch add() kernel on GPU\n","    // Notice that a and b are not pointers. Therefore the kernel call will\n","    // copy their values but the variables inside the kernel will not be the same.\n","    // If we modify a and b inside the kernel, it will not change a and b in this\n","    // Host code. This, indeed is the same behavior as any C/C++ function call.\n","    // In the case of d_c, it will copy the pointer contained in d_c, \n","    // so we will be able to modify the contents of d_c from the kernel. But to read \n","    // them from this Host code, we will have to do something else.\n","    add<<<1,1>>>(a, b, d_c);\n","    CU_CHECK_LAST_ERROR;\n","\n","    CU_CHECK(\n","        // Copy result back to host\n","        cudaMemcpy(&h_c, d_c, dataSize, cudaMemcpyDeviceToHost)\n","    );\n","\n","    int numDevs=0;\n","    CU_CHECK(\n","        cudaGetDeviceCount(&numDevs)\n","    );\n","\n","    cudaDeviceProp prop;\n","    CU_CHECK(\n","        cudaGetDeviceProperties(&prop, 0)\n","    );\n","    printf(\"Device Number: %d\\n\", 0);\n","    printf(\"  Device name: %s\\n\", prop.name);\n","    printf(\"  Memory Clock Rate (KHz): %d\\n\",\n","          prop.memoryClockRate);\n","    printf(\"  Memory Bus Width (bits): %d\\n\",\n","          prop.memoryBusWidth);\n","    printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n","          2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n","    printf(\"Num devices %d\\n\", numDevs);\n","\n","    printf(\"Result of multiplying %d * %d is %d\\n\",a,b,h_c);\n","    // Cleanup\n","    CU_CHECK(\n","      cudaFree(d_c)\n","    );\n","    return 0;\n","}"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Device Number: 0\n","  Device name: Tesla K80\n","  Memory Clock Rate (KHz): 2505000\n","  Memory Bus Width (bits): 384\n","  Peak Memory Bandwidth (GB/s): 240.480000\n","\n","Num devices 1\n","Result of multiplying 3 * 5 is 15\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ajyZJvBCZR7p","colab_type":"text"},"source":["Ok, cool! But what if I want to have some code in a .h file, the cuda kernels in an other .h file, and include both so that I can reuse code?\n","\n","Ok, let's try to put the macros and cuCheck function in a .h file, the kernel in an other .h file and the rest in a .cu file, and compile and execute everything. "]},{"cell_type":"code","metadata":{"id":"SlObGBaEZ5M7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441394529,"user_tz":-120,"elapsed":18259,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"589cbe58-8582-4f22-f069-0a9c00616778"},"source":["%%cuda --name utils.h\n","#include <iostream>\n","\n","void cuCheck(cudaError_t err, const std::string message = \"CUDA error:\") {\n","  if(err!=cudaSuccess) {\n","    std::cout << message << \" ERROR \" << cudaGetErrorString(err) << std::endl;\n","  }\n","}\n","#define CU_CHECK(a) cuCheck(a)\n","#define CU_CHECK2(a, b) cuCheck(a, b)\n","#define CU_CHECK_LAST_ERROR cuCheck(cudaGetLastError())"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/utils.h'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"DEoYz9uug7om","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441394531,"user_tz":-120,"elapsed":18234,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"b0adfae8-5582-44fe-dd0f-735fed4121c6"},"source":["%%cuda --name kernels.h\n","__global__ void add(int a, int b, int* __restrict d_c) {\n","    *d_c = a * b;\n","}"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/kernels.h'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"WdHjgZRHlSGe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1593441395984,"user_tz":-120,"elapsed":19635,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"391fe262-8e98-42e3-91cf-2d14c5463e42"},"source":["%%cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include \"/content/src/utils.h\"\n","#include \"/content/src/kernels.h\"\n","\n","// Host code\n","int main() {\n","    int a = 3, b = 5, h_c = 0;\n","    int *d_c;\n","    int dataSize = sizeof(int);\n","    CU_CHECK(cudaMalloc((void **)&d_c, dataSize));\n","    add<<<1,1>>>(a, b, d_c);\n","    CU_CHECK_LAST_ERROR;\n","    CU_CHECK(cudaMemcpy(&h_c, d_c, dataSize, cudaMemcpyDeviceToHost));\n","    int numDevs=0;\n","    CU_CHECK(cudaGetDeviceCount(&numDevs));\n","    cudaDeviceProp prop;\n","    CU_CHECK(cudaGetDeviceProperties(&prop, 0));\n","    printf(\"Device Number: %d\\n\", 0);\n","    printf(\"  Device name: %s\\n\", prop.name);\n","    printf(\"  Memory Clock Rate (KHz): %d\\n\",\n","          prop.memoryClockRate);\n","    printf(\"  Memory Bus Width (bits): %d\\n\",\n","          prop.memoryBusWidth);\n","    printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n","          2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n","    printf(\"Num devices %d\\n\", numDevs);\n","    printf(\"Result of multiplying %d * %d is %d\\n\",a,b,h_c);\n","    CU_CHECK(cudaFree(d_c));\n","    return 0;\n","}"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Device Number: 0\n","  Device name: Tesla K80\n","  Memory Clock Rate (KHz): 2505000\n","  Memory Bus Width (bits): 384\n","  Peak Memory Bandwidth (GB/s): 240.480000\n","\n","Num devices 1\n","Result of multiplying 3 * 5 is 15\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a8rWgfJ8hN3m","colab_type":"text"},"source":["VERY IMPORTANT!!! On each Colab session, the GPU that Google Colab provides can be different. Take it into account when you perform experiments, so that you compare results for the same GPU.\n","\n","If you have to repeat all the experiments, well, it's not that hard, just click play in all the code blocks one by one.\n","\n","Great!! Now we can start the lab :-D"]},{"cell_type":"markdown","metadata":{"id":"nX0Yv50Wh4nY","colab_type":"text"},"source":["##Section 1:\n","\n","Try to complete the following code, and make it compile. Remember that you have some slides and documents, and the CUDA API specification in the following link: https://docs.nvidia.com/cuda/cuda-runtime-api/index.html\n","\n","Also, you can search in Google, things like \"How to allocate CUDA memory\". And so on. Be brave! Is not so difficult.\n","\n","### First, complete the allocation functions."]},{"cell_type":"code","metadata":{"id":"u6Bj54YdVsjI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441395986,"user_tz":-120,"elapsed":19571,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"bb4b9ef3-e7f9-4975-bbf5-c7cd836872c2"},"source":["%%cuda --name memory_functions.h\n","void allocGPUData(int width, int height, uchar3** d_brg, uchar4** d_rgba){\n","  // Alloc gpu pointers\n","  CU_CHECK2(cudaMalloc(d_brg, sizeof(uchar3)*width*height), \"Alloc d_brg:\");\n","  // Can you finish this one? Replace cudaSucces with the proper cuda API call\n","  CU_CHECK2(cudaMalloc(d_rgba, sizeof(uchar4)*width*height), \"Alloc d_rgba:\");\n","}\n","void copyAndInitializeGPUData(int width, int height, uchar3* h_brg, uchar3* d_brg, uchar4* d_rgba, cudaStream_t stream=0) {\n","  // Copy data to GPU\n","  CU_CHECK2(cudaMemcpy(d_brg, h_brg, width*height*sizeof(uchar3), cudaMemcpyHostToDevice), \"Copy h_brg to d_brg:\");\n","  // Init output buffer to 0\n","  CU_CHECK2(cudaMemset(d_rgba, 0, width*height*sizeof(uchar4)), \"Memset d_rgba:\");\n","}\n","void freeCUDAPointers(uchar3* d_brg, uchar4* d_rgba) {\n","  // Free cuda pointers. Replace the cudaErrorInvalidValue flag\n","  // with the proper cuda API call, to free the GPU pointers\n","  CU_CHECK2(cudaFree(d_brg), \"Cuda free d_bgr:\");\n","  CU_CHECK2(cudaFree(d_rgba), \"Cuda free d_rgba:\");\n","  // Clean GPU device\n","  CU_CHECK2(cudaDeviceReset(), \"Cuda device reset:\");\n","}"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/memory_functions.h'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"s30mTBEIWcX6","colab_type":"text"},"source":["### When completed, test that they work with this small main function. If you execute it without completing the previous code, it will show some errors."]},{"cell_type":"code","metadata":{"id":"Tup9fxlwWl64","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593441397765,"user_tz":-120,"elapsed":21309,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"e5b4a406-3aed-4bd7-8392-a16bd5dc927c"},"source":["%%cu\n","#include <cuda.h>\n","#include \"/content/src/utils.h\"\n","#include \"/content/src/memory_functions.h\"\n","\n","#define WIDTH 10\n","#define HEIGHT 10\n","\n","int main() {\n","\n","  uchar3 *h_brg, *d_brg;\n","  uchar4 *h_rgba, *d_rgba;\n","\n","  h_brg = (uchar3*)malloc(sizeof(uchar3)*WIDTH*HEIGHT);\n","  h_rgba = (uchar4*)malloc(sizeof(uchar4)*WIDTH*HEIGHT);\n","\n","  allocGPUData(WIDTH, HEIGHT, &d_brg, &d_rgba);\n","  copyAndInitializeGPUData(WIDTH, HEIGHT, h_brg, d_brg, d_rgba);\n","  freeCUDAPointers(d_brg, d_rgba);\n","\n","  return 0;\n","}"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cSfdiwiHZKPT","colab_type":"text"},"source":["### Ok, now that we have the allocation, copy and free functions implemented, let's continue with the CPU function that will check the results. This one it's already implemented, you only need to click play to have it available."]},{"cell_type":"code","metadata":{"id":"2fywcbihaBaR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441397767,"user_tz":-120,"elapsed":21258,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"4693832a-b917-4d26-fea5-6a8ade05a125"},"source":["%%cuda --name check_results.h\n","bool checkResults(uchar4* rgba, uchar3* brg, int size) {\n","  bool correct = true;\n","  for (int i=0; i < size; ++i) {\n","    // In case you want to see actual values\n","    if (i==0 || i==1 || i==(size-1) ) {\n","      unsigned char x, y, z, w;\n","      x = rgba[i].x;\n","      y = rgba[i].y;\n","      z = rgba[i].z;\n","      w = rgba[i].w;\n","      std::cout << \"First position x=\" << (unsigned int)x << \" y=\" << (unsigned int)y << \" z=\" << (unsigned int)z << \" w=\" << (unsigned int)w << std::endl;\n","    }\n","    correct &= rgba[i].x == brg[i].y;\n","    correct &= rgba[i].y == brg[i].z;\n","    correct &= rgba[i].z == brg[i].x;\n","    correct &= rgba[i].w == 255;\n","    /*if(!correct)\n","    {\n","        std::cout << \"First position x=\" << (unsigned int)rgba[i].x << \" y=\" << (unsigned int)rgba[i].y << \" z=\" << (unsigned int)rgba[i].z << \" w=\" << (unsigned int)rgba[i].w << std::endl;\n","        correct = true;\n","    }*/\n","  }\n","  return correct;\n","}"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/check_results.h'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"Dl-YagCWaZOS","colab_type":"text"},"source":["### Now the interesting part, the kernel and the code to configure and launch it. The kernel it's almost exactly the same code as the OpenMP lab, only we replaced the forloops with something that you need to implement.\n","\n","Remember, that we have threads with indexes. This indexes are used to tell each CUDA thread, which data do they have to read or write.\n","\n","The structs that contain those indexes are in the documentation you have available in campusvirtual. Please check the docs."]},{"cell_type":"code","metadata":{"id":"Et3Bww3PbMgw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441397768,"user_tz":-120,"elapsed":21203,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"fbd1e39a-7831-4880-8a20-db6e837fc1a8"},"source":["%%cuda --name cuda_launcher.h\n","#include <stdio.h>\n","\n","\n","// BIDIMENSIONAL KERNEL\n","__global__ void convertBRG2RGBA(uchar3 *brg, uchar4* rgba, int width, int height) {\n","  int x = threadIdx.x + (blockIdx.x * blockDim.x); //Use the thread id and block id's to compute x \n","  int y = threadIdx.y + (blockIdx.y * blockDim.y); //Use the thread id and block id's to compute y\n","\n","\t// Protection to avoid segmentation fault\n","\tif (x < width && y < height) {\t\n","\t    rgba[width * y + x].x = brg[width * y + x].y;\n","\t    rgba[width * y + x].y = brg[width * y + x].z;\n","\t    rgba[width * y + x].z = brg[width * y + x].x;\n","\t    rgba[width * y + x].w = 255;\n","\t}\n","}\n","\n","void executeKernelconvertBRG2RGBA(int width, int height, uchar3* d_brg, uchar4* d_rgba, int numIters, cudaStream_t stream=0) {\n","  // Execute the GPU kernel\n","  dim3 block(256, 4, 1);\n","  dim3 grid(ceil(width/(float)block.x),ceil(height/(float)block.y) , 1);\n","\n","  auto t1 = std::chrono::high_resolution_clock::now();\n","  for (int i=0; i<numIters; ++i) {\n","    convertBRG2RGBA<<<grid, block, 0, stream>>>(d_brg, d_rgba, width, height);\n","  }\n","  CU_CHECK2(cudaDeviceSynchronize(), \"cudaDeviceSynchronize:\");\n","  auto t2 = std::chrono::high_resolution_clock::now();\n","  auto duration = std::chrono::duration_cast<std::chrono::microseconds>( t2 - t1 ).count();\n","  FILE* fp = fopen(\"dades.txt\", \"a\");\n","  fprintf(fp, \"%lf\\n\", (double) duration);\n","  fclose(fp);\n","  std::cout << \"convertBRG2RGBA time for \" << numIters << \" iterations = \"<< duration << \"us\" << std::endl;\n","}"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/cuda_launcher.h'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Nt2Ty-GmcSY_","colab_type":"text"},"source":["### MAIN EXPERIMENT \n","Try all the previous code, with the following main. If you did not finish all the previous code, this file will show some execution errors.\n","\n","The code is divided in two parts, one to define the parameters of the experiment and the other one is the main function with the experiment it self.\n","\n","The experiment is the code that creates a BRG image in CPU, allocates GPU memory, copies the BRG image to GPU memory, and executes a GPU kernel to convert the BRG image into a RGBA image. The output of the kernel is another GPU pointer, so after the kernel execution, we have to copy back the results."]},{"cell_type":"code","metadata":{"id":"FwcU52z8B--N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441397771,"user_tz":-120,"elapsed":21164,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"931a7648-37ee-4618-a337-21066350e3ab"},"source":["%%cuda --name experiment_settings.h\n","#pragma once\n","#define WIDTH 3840\n","#define HEIGHT 2160\n","#define EXPERIMENT_ITERATIONS 1000"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/experiment_settings.h'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"ZT9ep3h_ijOO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441397772,"user_tz":-120,"elapsed":21123,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"dcccf5ae-8d62-41bf-9047-75ddc08cb0f4"},"source":["%%cuda --name experiment.h\n","#include <cuda.h>\n","#include <chrono>\n","#include \"/content/src/utils.h\"\n","#include \"/content/src/memory_functions.h\"\n","#include \"/content/src/check_results.h\"\n","#include \"/content/src/cuda_launcher.h\"\n","#include \"/content/src/experiment_settings.h\"\n","\n","void executeExperiment() {\n","  uchar3 *h_brg, *d_brg;\n","  uchar4 *h_rgba, *d_rgba;\n","\n","  int bar_widht = HEIGHT/3;\n","\n","  // Alloc and generate BRG bars.\n","  h_brg = (uchar3*)malloc(sizeof(uchar3)*WIDTH*HEIGHT);\n","  for (int i=0; i < WIDTH * HEIGHT; ++i) {\n","    if (i < bar_widht) {\n","      uchar3 temp = {255, 0, 0};\n","      h_brg[i] = temp; \n","    } else if (i < bar_widht*2) {\n","      uchar3 temp = {0, 255, 0};\n","      h_brg[i] = temp;\n","    } else { \n","      uchar3 temp = {0, 0, 255};\n","      h_brg[i] = temp;\n","    }\n","  }\n","\n","  // Alloc RGBA pointers\n","  h_rgba = (uchar4*)malloc(sizeof(uchar4)*WIDTH*HEIGHT);\n","\n","  // Alloc gpu pointers\n","  allocGPUData(WIDTH, HEIGHT, &d_brg, &d_rgba);\n","  \n","  // Prepare and copy data to GPU\n","  copyAndInitializeGPUData(WIDTH, HEIGHT, h_brg, d_brg, d_rgba);\n","\n","  // Execute the GPU kernel\n","  executeKernelconvertBRG2RGBA(WIDTH, HEIGHT, d_brg, d_rgba, EXPERIMENT_ITERATIONS);\n","\n","  // Copy data back from GPU to CPU, without streams\n","  CU_CHECK2(cudaMemcpy(h_rgba, d_rgba, sizeof(uchar4)*WIDTH*HEIGHT, cudaMemcpyDeviceToHost), \"Cuda memcpy Device to Host: \");\n","    \n","  // Check results\n","  bool ok = checkResults(h_rgba, h_brg, WIDTH*HEIGHT);\n","  if (ok) {\n","      std::cout << \"Executed!! Results OK.\" << std::endl;\n","  } else {\n","      std::cout << \"Executed!! Results NOT OK.\" << std::endl;\n","  }\n","\n","  // Free CPU pointers\n","  free(h_rgba);\n","  free(h_brg);\n","\n","  // Free cuda pointers\n","  freeCUDAPointers(d_brg, d_rgba);\n","}"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/experiment.h'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"P5RA9zDI7Z0V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1593441400700,"user_tz":-120,"elapsed":24016,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"c8b213ad-6b8a-46a0-c9ca-608e0992757d"},"source":["%%cu\n","#include \"/content/src/experiment.h\"\n","int main() {\n","\n","  executeExperiment();\n","\n","  return 0;\n","}"],"execution_count":13,"outputs":[{"output_type":"stream","text":["convertBRG2RGBA time for 1000 iterations = 761876us\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=255 z=0 w=255\n","Executed!! Results OK.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3GqpbCcVdK83","colab_type":"text"},"source":["##Section 2:\n","Implement a version of the kernel and launcher that uses a one dimensional cuda GRID. That is, there is no more x and y, only x.\n","\n","Modify the code below, click play, and then click play in the Main Experiment block, in Section 1.\n","\n","Try different values of BLOCK_SIZE.\n","\n","Check if there is any execution time improvement, compared to Section 1.\n"]},{"cell_type":"code","metadata":{"id":"gLPY7trNd1SG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441400701,"user_tz":-120,"elapsed":23967,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"d070cfb7-1e55-4e69-df8d-3dfc7740f0e0"},"source":["%%cuda --name cuda_launcher.h\n","\n","#define BLOCK_SIZE 256\n","\n","// UNIDIMENSIONAL KERNEL\n","__global__ void convertBRG2RGBA(uchar3 *brg, uchar4* rgba, int width, int height) {\n","  int x = threadIdx.x + (blockIdx.x * blockDim.x); //Use the thread id and block id's to compute x \n","  \n","\t// Protection to avoid segmentation fault\n","\tif (x < width * height) {\t\n","\t    rgba[x].x = brg[x].y;\n","\t    rgba[x].y = brg[x].z;\n","\t    rgba[x].z = brg[x].x;\n","\t    rgba[x].w = 255;\n","\t}\n","}\n","\n","void executeKernelconvertBRG2RGBA(int width, int height, uchar3* d_brg, uchar4* d_rgba, int numIters, cudaStream_t stream=0) {\n","  // Execute the GPU kernel\n","  dim3 block(BLOCK_SIZE, 1, 1);\n","  dim3 grid(ceil(width*height/(float)block.x), 1, 1);\n","\n","  auto t1 = std::chrono::high_resolution_clock::now();\n","  for (int i=0; i<numIters; ++i) {\n","    convertBRG2RGBA<<<grid, block, 0, stream>>>(d_brg, d_rgba, width, height);\n","  }\n","  CU_CHECK2(cudaDeviceSynchronize(), \"cudaDeviceSynchronize:\");\n","  auto t2 = std::chrono::high_resolution_clock::now();\n","  auto duration = std::chrono::duration_cast<std::chrono::microseconds>( t2 - t1 ).count();\n","  FILE* fp = fopen(\"dades.txt\", \"a\");\n","  fprintf(fp, \"%lf\\n\", (double) duration);\n","  fclose(fp);\n","  std::cout << \"convertBRG2RGBA time for \" << numIters << \" iterations = \"<< duration << \"us\" << std::endl;\n","}"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/cuda_launcher.h'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ozsLq2rt__xl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1593441403424,"user_tz":-120,"elapsed":26651,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"d2eedc02-33a8-41e5-c9e8-f4b24a6fc918"},"source":["%%cu\n","#include \"/content/src/experiment.h\"\n","int main() {\n","\n","  executeExperiment();\n","\n","  return 0;\n","}"],"execution_count":15,"outputs":[{"output_type":"stream","text":["convertBRG2RGBA time for 1000 iterations = 585740us\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=255 z=0 w=255\n","Executed!! Results OK.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ExMCHf_RD3Wd","colab_type":"text"},"source":["Change the experiment settings, by executing more iterations and compare the unidimensional kernel with the bidimensional kernel.\n","\n","Comment the results in the report."]},{"cell_type":"code","metadata":{"id":"02hd2qlUEOsg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441403426,"user_tz":-120,"elapsed":26622,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"6c9dc6dd-979e-4e93-9c98-87dfd5603175"},"source":["%%cuda --name experiment_settings.h\n","#pragma once\n","#define WIDTH 3840\n","#define HEIGHT 2160\n","#define EXPERIMENT_ITERATIONS 1000 //try different values"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/experiment_settings.h'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"E3gBy530ektk","colab_type":"text"},"source":["## Section 3:\n","\n","Starting from Section 2, (use the best BLOCK_SIZE you found) try to optimize the memory accesses in some way, without using shared memory.\n","\n","Comment in the report which memory access problems you observe. Are the memory accesses aligned, and therfore coalesced?\n","\n","Remember that opposite to what the CPU compilers do, the nvcc compiler does not optimize the memory accesses in structs\n","\n","Remember also that GPU memory is organized in blocks of 4 bytes, and any array based on data elements that are not multiple of 2, will not be alligned. To be coalesced (specially in old architectures), it also has to be multiple of 4."]},{"cell_type":"code","metadata":{"id":"RmP4PDZ-e4lG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441403427,"user_tz":-120,"elapsed":26587,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"bba0f6ab-7051-44e0-d51d-0a58f21b6f8f"},"source":["%%cuda --name cuda_launcher.h\n","\n","#define BLOCK_SIZE 256\n","\n","// UNIDIMENSIONAL KERNEL BETTER MEMORY ACCESS\n","__global__ void convertBRG2RGBA(uchar3 *brg, uchar4* rgba, int width, int height) {\n","  int x = threadIdx.x + (blockIdx.x * blockDim.x); //Use the same code as in section 2 in this line\n","  \n","\t// Protection to avoid segmentation fault\n","\tif (x < width * height) {\t\n","\t    uchar3 tmp_3 = brg[x];\n","      /*uint3 tmp_3 = ((uint3*)brg)[x];\n","\n","      uchar4* tmp1 = (uchar4*)(&tmp_3.x);\n","      uchar4* tmp2 = (uchar4*)(&tmp_3.y);\n","      uchar4* tmp3 = (uchar4*)(&tmp_3.z);\n","\n","      \n","      uchar4 pix1 = make_uchar4(tmp1->y, tmp1->z, tmp1->x, 255);\n","      uchar4 pix2 = make_uchar4(tmp2->x, tmp2->y, tmp1->w, 255);\n","      uchar4 pix3 = make_uchar4(tmp2->w, tmp3->x, tmp2->z, 255);\n","      uchar4 pix4 = make_uchar4(tmp3->z, tmp3->w, tmp3->y, 255);\n","      ((uint4*)rgba)[x] = make_uint4(*(uint*)(&pix1), *(uint*)(&pix2), *(uint*)(&pix3), *(uint*)(&pix4));*/\n","\n","      uchar4 tmp_4;\n","      \n","      tmp_4.x = tmp_3.y;\n","      tmp_4.y = tmp_3.z;\n","      tmp_4.z = tmp_3.x;\n","      tmp_4.w = 255;\n","      \n","      rgba[x] = tmp_4;\n","\t}\n","}\n","\n","void executeKernelconvertBRG2RGBA(int width, int height, uchar3* d_brg, uchar4* d_rgba, int numIters, cudaStream_t stream=0) {\n","  // Execute the GPU kernel\n","  dim3 block(BLOCK_SIZE, 1, 1);\n","  dim3 grid(ceil(width*height/(float)block.x), 1, 1);\n","  //dim3 grid(ceil(((width*height)/4)/(float)block.x), 1, 1);\n","\n","  auto t1 = std::chrono::high_resolution_clock::now();\n","  for (int i=0; i<numIters; ++i) {\n","    convertBRG2RGBA<<<grid, block, 0, stream>>>(d_brg, d_rgba, width, height);\n","  }\n","  CU_CHECK2(cudaDeviceSynchronize(), \"cudaDeviceSynchronize:\");\n","  auto t2 = std::chrono::high_resolution_clock::now();\n","  auto duration = std::chrono::duration_cast<std::chrono::microseconds>( t2 - t1 ).count();\n","  FILE* fp = fopen(\"dades.txt\", \"a\");\n","  fprintf(fp, \"%lf\\n\", (double) duration);\n","  fclose(fp);\n","  std::cout << \"convertBRG2RGBA time for \" << numIters << \" iterations = \"<< duration << \"us\" << std::endl;\n","}"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/cuda_launcher.h'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"dMDGsQjPAkIv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441403429,"user_tz":-120,"elapsed":26540,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"0036e90c-da5b-420c-8668-b2805623a981"},"source":["%%cuda --name test3.cu\n","#include \"/content/src/experiment.h\"\n","int main() {\n","\n","  executeExperiment();\n","\n","  return 0;\n","}"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/test3.cu'"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Ju7VOSl1_40V","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593441407523,"user_tz":-120,"elapsed":30630,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}}},"source":["!nvcc src/test3.cu -o test3"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDLTNvktAGOK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"status":"ok","timestamp":1593441411541,"user_tz":-120,"elapsed":34598,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"77ce0649-525f-4227-903b-c05f61854f11"},"source":["!nvprof ./test3"],"execution_count":20,"outputs":[{"output_type":"stream","text":["==415== NVPROF is profiling process 415, command: ./test3\n","convertBRG2RGBA time for 1000 iterations = 598954us\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=255 z=0 w=255\n","Executed!! Results OK.\n","==415== Profiling application: ./test3\n","==415== Profiling result:\n","            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n"," GPU activities:   96.12%  593.25ms      1000  593.25us  591.96us  599.00us  convertBRG2RGBA(uchar3*, uchar4*, int, int)\n","                    3.24%  19.994ms         1  19.994ms  19.994ms  19.994ms  [CUDA memcpy DtoH]\n","                    0.64%  3.9617ms         1  3.9617ms  3.9617ms  3.9617ms  [CUDA memcpy HtoD]\n","                    0.00%  1.3760us         1  1.3760us  1.3760us  1.3760us  [CUDA memset]\n","      API calls:   69.18%  591.73ms         1  591.73ms  591.73ms  591.73ms  cudaDeviceSynchronize\n","                   20.33%  173.91ms         2  86.954ms  252.43us  173.66ms  cudaMalloc\n","                    6.24%  53.335ms         1  53.335ms  53.335ms  53.335ms  cudaDeviceReset\n","                    2.94%  25.113ms         2  12.556ms  4.0617ms  21.051ms  cudaMemcpy\n","                    0.79%  6.7962ms      1000  6.7960us  5.2560us  405.40us  cudaLaunchKernel\n","                    0.41%  3.4804ms         2  1.7402ms  247.12us  3.2332ms  cudaFree\n","                    0.06%  501.96us         1  501.96us  501.96us  501.96us  cuDeviceTotalMem\n","                    0.05%  403.17us        97  4.1560us     158ns  224.69us  cuDeviceGetAttribute\n","                    0.01%  42.938us         1  42.938us  42.938us  42.938us  cudaMemset\n","                    0.00%  22.980us         1  22.980us  22.980us  22.980us  cuDeviceGetName\n","                    0.00%  3.1500us         1  3.1500us  3.1500us  3.1500us  cuDeviceGetPCIBusId\n","                    0.00%  2.0980us         3     699ns     179ns  1.1060us  cuDeviceGetCount\n","                    0.00%  1.7980us         2     899ns     365ns  1.4330us  cuDeviceGet\n","                    0.00%     297ns         1     297ns     297ns     297ns  cuDeviceGetUuid\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EPECp0T6IU0Z","colab_type":"text"},"source":["##Section 4:\n","Now optimize the GPU memory accesses so that each thread always reads at least one element of 4 bytes. Use shared memory to that end.\n","\n","Look at the PDF Lab2CUDA in the campus, an read the last two pages. There you have a graphical explanation of the kernel issues. For this section you only need to understand the first figure.\n","\n","About shared memory: we will refresh some concepts.\n","\n","Shared memory, is a kind of memory that is visible only by the cuda threads of a thread block. Cuda threads from different thread blocks can not see the shared memory of other threadblocks.\n","\n","Shared memory is a limited resource. Depending on the GPU model, you may have from 32KB to 64KB of shared memory. Additionally, this memory is not used only by one threadblock. It is partitioned in as many independent blocks as thread blocks can execute in a single Streaming Multiprocessor (check the documentation if you don't know what a SM is). \n","\n","So when you are defining the amount of shared memory you want, you are defining the amount of memory, every thread block will have available.\n","\n","If you reserve 64KB of shared memory, in a GPU that has this capacity, only one thread block will execute on each SM, which is super slow. Each SM can concurrently execute from 8 to 32 thread blocks. For the best performance, you usually want the greatest amount of thread blocks active on each SM.\n","\n","Therefore, you what to use the least shared memory possible, and only use it when it has clear benefits.\n"]},{"cell_type":"code","metadata":{"id":"MKRs22QeIvwj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441411544,"user_tz":-120,"elapsed":34557,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"23a65721-ff1b-4107-ff85-b37bece939a7"},"source":["%%cuda --name cuda_launcher.h\n","#include \"/content/src/experiment_settings.h\"\n","\n","// Try different vaues of BLOCK_SIZE\n","#define BLOCK_SIZE 256\n","\n","// Number of 4 byte elements that we can make out of BLOCK_SIZE elements of 3 bytes\n","#define N_ELEMS_3_4_TBLOCK (BLOCK_SIZE * 3)/4\n","#define N_ELEMS_3_4_IMAGE (WIDTH*HEIGHT * 3)/4\n","\n","// UNIDIMENSIONAL KERNEL SHARED MEMORY\n","__global__ void convertBRG2RGBA(uchar3 *brg, uchar4* rgba, int width, int height) {\n","  int position = threadIdx.x + (blockIdx.x * N_ELEMS_3_4_TBLOCK);// use N_ELEMS_3_4_TBLOCK to compute the position of each thread when we read brg as if it had elements of 4 bytes\n","  __shared__ uchar4 bgrShared[N_ELEMS_3_4_TBLOCK];\n","  \n","  if(threadIdx.x < N_ELEMS_3_4_TBLOCK && position < N_ELEMS_3_4_IMAGE) {\n","      bgrShared[threadIdx.x] = reinterpret_cast<uchar4*>(brg)[position];\n","  }\n","\n","  __syncthreads();\n","  \n","  position = threadIdx.x + (blockIdx.x * blockDim.x); // recompute position without N_ELEMS_3_4_TBLOCK to write the results\n","\t// Protection to avoid segmentation fault\n","\tif (position < width*height) {\t\n","        uchar3 local = reinterpret_cast<uchar3*>(bgrShared)[threadIdx.x];\n","        rgba[position] = make_uchar4(local.y,local.z,local.x,255);\n","\t}\n","}\n","\n","void executeKernelconvertBRG2RGBA(int width, int height, uchar3* d_brg, uchar4* d_rgba, int numIters, cudaStream_t stream=0) {\n","  // Execute the GPU kernel\n","  dim3 block(BLOCK_SIZE, 1, 1);\n","  dim3 grid(ceil(width*height/(float)block.x), 1, 1);\n","\n","  auto t1 = std::chrono::high_resolution_clock::now();\n","  for (int i=0; i<numIters; ++i) {\n","    convertBRG2RGBA<<<grid, block, 0, stream>>>(d_brg, d_rgba, width, height);\n","  }\n","  CU_CHECK2(cudaDeviceSynchronize(), \"cudaDeviceSynchronize:\");\n","  auto t2 = std::chrono::high_resolution_clock::now();\n","  auto duration = std::chrono::duration_cast<std::chrono::microseconds>( t2 - t1 ).count();\n","  FILE* fp = fopen(\"dades.txt\", \"a\");\n","  fprintf(fp, \"%lf\\n\", (double) duration);\n","  fclose(fp);\n","  std::cout << \"convertBRG2RGBA time for \" << numIters << \" iterations = \"<< duration << \"us\" << std::endl;\n","}"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/cuda_launcher.h'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"4E_ErYqLAtVU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441411545,"user_tz":-120,"elapsed":34519,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"f4064b85-7a7b-4cd7-c23e-27f89325e0a1"},"source":["%%cuda --name section_4.cu\n","#include \"/content/src/experiment.h\"\n","int main() {\n","\n","  executeExperiment();\n","\n","  return 0;\n","}"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/section_4.cu'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"GifNYIbXs1F4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593441415824,"user_tz":-120,"elapsed":38784,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}}},"source":["!nvcc src/section_4.cu -o section_4"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-QNQsaitFcn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593441419183,"user_tz":-120,"elapsed":42100,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"a08a9e16-429d-4d69-fdff-90066997ae9a"},"source":["!nvprof ./section_4 2> a.txt"],"execution_count":24,"outputs":[{"output_type":"stream","text":["convertBRG2RGBA time for 1000 iterations = 613551us\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=255 z=0 w=255\n","Executed!! Results OK.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SIweqX0nu_v8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1593441423085,"user_tz":-120,"elapsed":45979,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"1660f6fb-cd50-476f-b33e-c460824b9598"},"source":["!cat a.txt\n","!cat dades.txt"],"execution_count":25,"outputs":[{"output_type":"stream","text":["==467== NVPROF is profiling process 467, command: ./section_4\n","==467== Profiling application: ./section_4\n","==467== Profiling result:\n","            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n"," GPU activities:   96.13%  607.79ms      1000  607.79us  606.29us  612.41us  convertBRG2RGBA(uchar3*, uchar4*, int, int)\n","                    3.27%  20.674ms         1  20.674ms  20.674ms  20.674ms  [CUDA memcpy DtoH]\n","                    0.60%  3.7852ms         1  3.7852ms  3.7852ms  3.7852ms  [CUDA memcpy HtoD]\n","                    0.00%  1.5040us         1  1.5040us  1.5040us  1.5040us  [CUDA memset]\n","      API calls:   75.27%  606.88ms         1  606.88ms  606.88ms  606.88ms  cudaDeviceSynchronize\n","                   13.90%  112.07ms         2  56.035ms  143.76us  111.93ms  cudaMalloc\n","                    6.34%  51.130ms         1  51.130ms  51.130ms  51.130ms  cudaDeviceReset\n","                    3.17%  25.550ms         2  12.775ms  3.8071ms  21.743ms  cudaMemcpy\n","                    0.78%  6.2628ms      1000  6.2620us  4.8150us  426.55us  cudaLaunchKernel\n","                    0.42%  3.4238ms         2  1.7119ms  219.66us  3.2042ms  cudaFree\n","                    0.07%  528.32us         1  528.32us  528.32us  528.32us  cuDeviceTotalMem\n","                    0.04%  316.66us        97  3.2640us     159ns  144.30us  cuDeviceGetAttribute\n","                    0.01%  42.679us         1  42.679us  42.679us  42.679us  cudaMemset\n","                    0.00%  23.354us         1  23.354us  23.354us  23.354us  cuDeviceGetName\n","                    0.00%  3.6590us         1  3.6590us  3.6590us  3.6590us  cuDeviceGetPCIBusId\n","                    0.00%  2.6400us         3     880ns     209ns  1.5470us  cuDeviceGetCount\n","                    0.00%  1.9820us         2     991ns     642ns  1.3400us  cuDeviceGet\n","                    0.00%     331ns         1     331ns     331ns     331ns  cuDeviceGetUuid\n","761876.000000\n","585740.000000\n","598954.000000\n","613551.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sGPcLMKz6a0d","colab_type":"text"},"source":["##Section 5:\n","\n","Now, following the explanation in the Lab2CUDA, try to implement the described algorithm. Take into account that the piece of code that reads from temp variables and writes in pix_write, requires some changes."]},{"cell_type":"code","metadata":{"id":"2DvT4yBO6ck2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441423086,"user_tz":-120,"elapsed":45902,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"e34c78ac-4632-43b0-deed-b8b2a9de0b98"},"source":["%%cuda --name cuda_launcher.h\n","#include \"/content/src/experiment_settings.h\"\n","\n","// Try different vaues of BLOCK_SIZE\n","#define BLOCK_SIZE 256\n","\n","// Number of 4 byte elements that we can make out of BLOCK_SIZE elements of 3 bytes\n","#define N_ELEMS_3_4_TBLOCK (BLOCK_SIZE * 3)/4\n","#define N_ELEMS_3_4_IMAGE (WIDTH*HEIGHT * 3)/4\n","#define N_ELEMS_3_4_TBLOCK_3 N_ELEMS_3_4_TBLOCK/3\n","\n","// UNIDIMENSIONAL KERNEL SHARED MEMORY\n","__global__ void convertBRG2RGBA(uchar3 *brg, uchar4* rgba, int width, int height) {\n","  int position = threadIdx.x + (blockIdx.x * N_ELEMS_3_4_TBLOCK);// use N_ELEMS_3_4_TBLOCK to compute the position of each thread when we read brg as if it had elements of 4 bytes\n","  __shared__ uchar4 bgrShared[N_ELEMS_3_4_TBLOCK];\n","  \n","  if(threadIdx.x < N_ELEMS_3_4_TBLOCK && position < N_ELEMS_3_4_IMAGE) {\n","      bgrShared[threadIdx.x] = reinterpret_cast<uchar4*>(brg)[position];\n","  }\n","\n","  __syncthreads();\n","\n","  /* pix_write -> La memoria para acceso  */\n","  __shared__ uchar4 pix_write[1024];\n","\n","  /* Cada 3 threads escribimos los bytes a memoria compartida */\n","  if(threadIdx.x < N_ELEMS_3_4_TBLOCK_3)\n","  {\n","      /* Calculem els temp */\n","      uchar4 temp1, temp2, temp3;\n","      temp1 = bgrShared[3 * threadIdx.x];\n","      temp2 = bgrShared[3 * threadIdx.x + 1];\n","      temp3 = bgrShared[3 * threadIdx.x + 2];\n","\n","      int position2 = threadIdx.x + (blockIdx.x * N_ELEMS_3_4_TBLOCK_3);\n","\n","      /* Asignamos la memoria */\n","      pix_write[threadIdx.x * 4]     = make_uchar4(temp1.y, temp1.z, temp1.x, 255);\n","      pix_write[threadIdx.x * 4 + 1] = make_uchar4(temp2.x, temp2.y, temp1.w, 255);\n","      pix_write[threadIdx.x * 4 + 2] = make_uchar4(temp2.w, temp3.x, temp2.z, 255);\n","      pix_write[threadIdx.x * 4 + 3] = make_uchar4(temp3.z, temp3.w, temp3.y, 255);\n","   \n","      ((uint4*)rgba)[position2] = ((uint4*)pix_write)[threadIdx.x];\n","  }\n","}\n","\n","void executeKernelconvertBRG2RGBA(int width, int height, uchar3* d_brg, uchar4* d_rgba, int numIters, cudaStream_t stream=0) {\n","  // Execute the GPU kernel\n","  dim3 block(BLOCK_SIZE, 1, 1);\n","  dim3 grid(ceil(width*height/(float)block.x), 1, 1);\n","\n","  auto t1 = std::chrono::high_resolution_clock::now();\n","  for (int i=0; i<numIters; ++i) {\n","    convertBRG2RGBA<<<grid, block, 0, stream>>>(d_brg, d_rgba, width, height);\n","  }\n","  CU_CHECK2(cudaDeviceSynchronize(), \"cudaDeviceSynchronize:\");\n","  auto t2 = std::chrono::high_resolution_clock::now();\n","  auto duration = std::chrono::duration_cast<std::chrono::microseconds>( t2 - t1 ).count();\n","  FILE* fp = fopen(\"dades.txt\", \"a\");\n","  fprintf(fp, \"%lf\\n\", (double) duration);\n","  fclose(fp);\n","  std::cout << \"convertBRG2RGBA time for \" << numIters << \" iterations = \"<< duration << \"us\" << std::endl;\n","}"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/cuda_launcher.h'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"G-p5Lxq7II5t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441423087,"user_tz":-120,"elapsed":45856,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"1fc835da-461e-483e-83b0-7ab3fa999b2d"},"source":["%%cuda --name section_5.cu\n","#include \"/content/src/experiment.h\"\n","int main() {\n","\n","  executeExperiment();\n","\n","  return 0;\n","}"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/section_5.cu'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"J5O0rdnHsNqk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593441425840,"user_tz":-120,"elapsed":48605,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}}},"source":["!nvcc src/section_5.cu -o section_5"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ep38RfMcsiEZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"status":"ok","timestamp":1593441428776,"user_tz":-120,"elapsed":51506,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"73516730-d1ee-42b8-eb7c-a5a21a5e57ef"},"source":["!nvprof ./section_5"],"execution_count":29,"outputs":[{"output_type":"stream","text":["==520== NVPROF is profiling process 520, command: ./section_5\n","convertBRG2RGBA time for 1000 iterations = 683320us\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=255 z=0 w=255\n","Executed!! Results OK.\n","==520== Profiling application: ./section_5\n","==520== Profiling result:\n","            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n"," GPU activities:   96.52%  677.61ms      1000  677.61us  674.90us  684.12us  convertBRG2RGBA(uchar3*, uchar4*, int, int)\n","                    2.95%  20.727ms         1  20.727ms  20.727ms  20.727ms  [CUDA memcpy DtoH]\n","                    0.53%  3.7110ms         1  3.7110ms  3.7110ms  3.7110ms  [CUDA memcpy HtoD]\n","                    0.00%  1.3440us         1  1.3440us  1.3440us  1.3440us  [CUDA memset]\n","      API calls:   77.39%  676.51ms         1  676.51ms  676.51ms  676.51ms  cudaDeviceSynchronize\n","                   12.62%  110.34ms         2  55.171ms  189.96us  110.15ms  cudaMalloc\n","                    5.84%  51.084ms         1  51.084ms  51.084ms  51.084ms  cudaDeviceReset\n","                    2.92%  25.511ms         2  12.756ms  3.7555ms  21.756ms  cudaMemcpy\n","                    0.73%  6.3720ms      1000  6.3710us  4.8350us  420.74us  cudaLaunchKernel\n","                    0.40%  3.4604ms         2  1.7302ms  254.88us  3.2055ms  cudaFree\n","                    0.06%  526.45us         1  526.45us  526.45us  526.45us  cuDeviceTotalMem\n","                    0.03%  301.10us        97  3.1040us     158ns  133.10us  cuDeviceGetAttribute\n","                    0.00%  35.683us         1  35.683us  35.683us  35.683us  cudaMemset\n","                    0.00%  21.394us         1  21.394us  21.394us  21.394us  cuDeviceGetName\n","                    0.00%  3.0030us         1  3.0030us  3.0030us  3.0030us  cuDeviceGetPCIBusId\n","                    0.00%  2.2950us         3     765ns     181ns  1.2430us  cuDeviceGetCount\n","                    0.00%  1.3300us         2     665ns     290ns  1.0400us  cuDeviceGet\n","                    0.00%     321ns         1     321ns     321ns     321ns  cuDeviceGetUuid\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MazFSZvFO9lT","colab_type":"text"},"source":["##Section 6:\n","\n","Change all the host code necessary, to use cuda streams. Here you have an example."]},{"cell_type":"code","metadata":{"id":"3EvgoMT5PVYn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593441430788,"user_tz":-120,"elapsed":53452,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"fd2d3a5e-e0ba-4d7b-e283-747f30ced6c7"},"source":["%%cu\n","#include <iostream>\n","\n","__global__ void square(int* d_input, int* d_output) {\n","    int x = threadIdx.x + blockIdx.x * blockDim.x;\n","\n","    int val = d_input[x];\n","    // We exploit the temporal locality of the value stored in d_output[x]\n","    d_output[x] = val*val;\n","}\n","\n","static const size_t dataSize = sizeof(int)*1024;\n","\n","int main() {\n","    \n","    int *h_input, *h_output;\n","    h_input = (int*)malloc(dataSize);\n","    h_output = (int*)malloc(dataSize);\n","\n","    for (int i=0; i<1024; ++i) h_input[i]=i;\n","\n","    int *d_input, *d_output;\n","    cudaMalloc(&d_input, dataSize);\n","    cudaMalloc(&d_output, dataSize);\n","\n","    cudaStream_t stream;\n","    cudaStreamCreate(&stream);\n","\n","    dim3 block(512);\n","    dim3 grid(2);\n","\n","    // The CPU thread does not wait that any of the following actions finish\n","    // It only asks the GPU to do the copies and the kernel and continues\n","    cudaMemcpyAsync(d_input, h_input, dataSize, cudaMemcpyHostToDevice, stream);\n","    square<<<grid, block, 0, stream>>>(d_input, d_output);\n","    cudaMemcpyAsync(h_output, d_output, dataSize, cudaMemcpyDeviceToHost, stream);\n","\n","    // Here, we wait for all the orders enqueued in stream, to finish.\n","    cudaStreamSynchronize(stream);\n","\n","    bool correct = true;\n","    for (int i=0; i<1024; ++i) correct &= h_output[i] == i*i;\n","\n","    std::cout << \"Finished and results are \" << (correct ? \"correct.\" : \"not correct.\") << std::endl;\n","\n","    cudaStreamDestroy(stream);\n","    cudaFree(d_input);\n","    cudaFree(d_output);\n","    free(h_input);\n","    free(h_output);\n","\n","    return 0;\n","}"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Finished and results are correct.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P4VK6ylPWaEY","colab_type":"text"},"source":["Modify this code, to use streams"]},{"cell_type":"code","metadata":{"id":"yz3kVFkrWOlB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441430793,"user_tz":-120,"elapsed":53371,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"a1ed83af-fb3b-422d-c055-6e6ce3484b96"},"source":["%%cuda --name memory_functions.h\n","void allocGPUData(int width, int height, uchar3** d_brg, uchar4** d_rgba){\n","  // Alloc gpu pointers\n","  CU_CHECK2(cudaMalloc(d_brg, sizeof(uchar3)*width*height), \"Alloc d_brg:\");\n","  // Can you finish this one? Replace cudaSucces with the proper cuda API call\n","  CU_CHECK2(cudaMalloc(d_rgba, sizeof(uchar4)*width*height), \"Alloc d_rgba:\");\n","}\n","void copyAndInitializeGPUData(int width, int height, uchar3* h_brg, uchar3* d_brg, uchar4* d_rgba, cudaStream_t stream=0) {\n","  // Copy data to GPU\n","  CU_CHECK2(cudaMemcpyAsync(d_brg, h_brg, width*height*sizeof(uchar3), cudaMemcpyHostToDevice, stream), \"Copy h_brg to d_brg:\");\n","  // Init output buffer to 0\n","  CU_CHECK2(cudaMemsetAsync(d_rgba, 0, width*height*sizeof(uchar4), stream), \"Memset d_rgba:\");\n","}\n","void freeCUDAPointers(uchar3* d_brg, uchar4* d_rgba) {\n","  // Free cuda pointers. Replace the cudaErrorInvalidValue flag\n","  // with the proper cuda API call, to free the GPU pointers\n","  CU_CHECK2(cudaFree(d_brg), \"Cuda free d_bgr:\");\n","  CU_CHECK2(cudaFree(d_rgba), \"Cuda free d_rgba:\");\n","  // Clean GPU device\n","  CU_CHECK2(cudaDeviceReset(), \"Cuda device reset:\");\n","}"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/memory_functions.h'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"ymPFWGqkWew-","colab_type":"text"},"source":["And also modify this code, so that mem copies from CPU to GPU and from GPU to CPU use an stream, and are not blocking.\n","\n","Additionally, add a chrono between the first memcpy (included) and the cudaStreamSynchronize. This is the time you will have to compare.\n","\n","Follow the indications in the code."]},{"cell_type":"code","metadata":{"id":"AkGOy69ZgQZt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441430794,"user_tz":-120,"elapsed":53366,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"7fe0a9c3-dc8d-40f3-93c5-d91b134ba545"},"source":["%%cuda --name cuda_launcher.h\n","#include <stdio.h>\n","\n","\n","// BIDIMENSIONAL KERNEL\n","__global__ void convertBRG2RGBA(uchar3 *brg, uchar4* rgba, int width, int height) {\n","  int x = threadIdx.x + (blockIdx.x * blockDim.x); //Use the thread id and block id's to compute x \n","  int y = threadIdx.y + (blockIdx.y * blockDim.y); //Use the thread id and block id's to compute y\n","\n","\t// Protection to avoid segmentation fault\n","\tif (x < width && y < height) {\t\n","\t    rgba[width * y + x].x = brg[width * y + x].y;\n","\t    rgba[width * y + x].y = brg[width * y + x].z;\n","\t    rgba[width * y + x].z = brg[width * y + x].x;\n","\t    rgba[width * y + x].w = 255;\n","\t}\n","}\n","\n","void executeKernelconvertBRG2RGBA(int width, int height, uchar3* d_brg, uchar4* d_rgba, int numIters, cudaStream_t stream=0) {\n","  // Execute the GPU kernel\n","  dim3 block(256, 4, 1);\n","  dim3 grid(ceil(width/(float)block.x),ceil(height/(float)block.y) , 1);\n","\n","  auto t1 = std::chrono::high_resolution_clock::now();\n","  for (int i=0; i<numIters; ++i) {\n","    convertBRG2RGBA<<<grid, block, 0, stream>>>(d_brg, d_rgba, width, height);\n","  }\n","  CU_CHECK2(cudaDeviceSynchronize(), \"cudaDeviceSynchronize:\");\n","  auto t2 = std::chrono::high_resolution_clock::now();\n","  auto duration = std::chrono::duration_cast<std::chrono::microseconds>( t2 - t1 ).count();\n","  FILE* fp = fopen(\"dades.txt\", \"a\");\n","  fprintf(fp, \"%lf\\n\", (double) duration);\n","  fclose(fp);\n","  std::cout << \"convertBRG2RGBA time for \" << numIters << \" iterations = \"<< duration << \"us\" << std::endl;\n","}"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/cuda_launcher.h'"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"ih1ADZpjWeFk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593441430795,"user_tz":-120,"elapsed":53297,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"cd556fa6-b035-4b8a-bf99-be8037edbe44"},"source":["%%cuda --name experiment.h\n","#include <cuda.h>\n","#include <chrono>\n","#include \"/content/src/utils.h\"\n","#include \"/content/src/memory_functions.h\"\n","#include \"/content/src/check_results.h\"\n","#include \"/content/src/cuda_launcher.h\"\n","#include \"/content/src/experiment_settings.h\"\n","\n","void executeExperiment() {\n","  uchar3 *h_brg, *d_brg;\n","  uchar4 *h_rgba, *d_rgba;\n","\n","  int bar_widht = HEIGHT/3;\n","\n","  // Alloc and generate BRG bars.\n","  h_brg = (uchar3*)malloc(sizeof(uchar3)*WIDTH*HEIGHT);\n","  for (int i=0; i < WIDTH * HEIGHT; ++i) {\n","    if (i < bar_widht) {\n","      uchar3 temp = {255, 0, 0};\n","      h_brg[i] = temp; \n","    } else if (i < bar_widht*2) {\n","      uchar3 temp = {0, 255, 0};\n","      h_brg[i] = temp;\n","    } else { \n","      uchar3 temp = {0, 0, 255};\n","      h_brg[i] = temp;\n","    }\n","  }\n","\n","  cudaStream_t stream;\n","  cudaStreamCreate(&stream);\n","\n","  // Alloc RGBA pointers\n","  h_rgba = (uchar4*)malloc(sizeof(uchar4)*WIDTH*HEIGHT);\n","\n","  // Alloc gpu pointers\n","  allocGPUData(WIDTH, HEIGHT, &d_brg, &d_rgba);\n","  \n","  // Start measuring time here\n","  copyAndInitializeGPUData(WIDTH, HEIGHT, h_brg, d_brg, d_rgba, stream);\n","\n","  // Execute the GPU kernel\n","  executeKernelconvertBRG2RGBA(WIDTH, HEIGHT, d_brg, d_rgba, EXPERIMENT_ITERATIONS, stream);\n","\n","  // Copy data back from GPU to CPU\n","  CU_CHECK2(cudaMemcpyAsync(h_rgba, d_rgba, sizeof(uchar4)*WIDTH*HEIGHT, cudaMemcpyDeviceToHost, stream), \"Cuda memcpy Device to Host: \");\n","\n","  // Synchronize the stream here\n","  cudaStreamSynchronize(stream);\n","  // Stop measuring time here, and print it\n","  \n","    \n","  // Check results\n","  bool ok = checkResults(h_rgba, h_brg, WIDTH*HEIGHT);\n","  if (ok) {\n","      std::cout << \"Executed!! Results OK.\" << std::endl;\n","  } else {\n","      std::cout << \"Executed!! Results NOT OK.\" << std::endl;\n","  }\n","\n","  // Free CPU pointers\n","  free(h_rgba);\n","  free(h_brg);\n","\n","  // Free cuda pointers\n","  freeCUDAPointers(d_brg, d_rgba);\n","}"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'File written in /content/src/experiment.h'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"4Cb3WvwUW6E7","colab_type":"text"},"source":["Do the following:\n","\n","1.   Use the fastest kernel version.\n","2.   Use number of iterations = 1.\n","3.   Compare the same kernel, with the original Host code, and this new Host code.\n","4.   To do so, you can use the code you do now, you only need to set stream=0 in order to simulate the original code.\n","5.   Execute it with the following code.\n","6.   Compare and try to explain the performance difference in the report.\n"]},{"cell_type":"code","metadata":{"id":"icJq5yuCW9f_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1593441433384,"user_tz":-120,"elapsed":55838,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"d4f50da6-39f9-4410-dc54-694346e6829b"},"source":["%%cu\n","#include \"/content/src/experiment.h\"\n","int main() {\n","\n","  executeExperiment();\n","\n","  return 0;\n","}"],"execution_count":34,"outputs":[{"output_type":"stream","text":["convertBRG2RGBA time for 1000 iterations = 3288us\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=0 z=255 w=255\n","First position x=0 y=255 z=0 w=255\n","Executed!! Results OK.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1FIPUf9Z-5lB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1593441435937,"user_tz":-120,"elapsed":58354,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"c2bd5594-5fae-4b7f-9a88-2eeb42e576e5"},"source":["!cat dades.txt"],"execution_count":35,"outputs":[{"output_type":"stream","text":["761876.000000\n","585740.000000\n","598954.000000\n","613551.000000\n","683320.000000\n","3288.000000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZLyRkpQsAWbl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"status":"ok","timestamp":1593441435938,"user_tz":-120,"elapsed":58310,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}},"outputId":"67d20b3f-78a8-4872-ac4c-802fa27b1b94"},"source":["\"\"\"\n","Script en python per a visualitzar una comparativa entre els resultats.\n","\"\"\"\n","\n","import matplotlib.pyplot as plt; plt.rcdefaults()\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def get_array_from_file(filename: str) -> list:\n","  with open(filename, \"r\") as f:\n","    arr = [int(line.split(\".\")[0]) for line in f]\n","  return arr\n","\n","\n","objects = ('Section 1', 'Section 2', 'Section 3', 'Section 4', 'Section 5', 'Section 6')\n","y_pos = np.arange(len(objects))\n","performance = get_array_from_file(\"dades.txt\")\n","\n","plt.bar(y_pos, performance, align='center', alpha=0.5)\n","plt.xticks(y_pos, objects)\n","plt.ylabel('Temps per solucionar el problema')\n","plt.title('Rapidesa per secció en us (per 1000 iteracions)')\n","\n","plt.show()"],"execution_count":36,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"E7xEU6iRpkE8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593441435939,"user_tz":-120,"elapsed":58304,"user":{"displayName":"Johnny Núñez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gho-YF5utbbxU9BXzJrkFilZupPaPeSl7QTJ8T2xQ=s64","userId":"00414033458499193534"}}},"source":[""],"execution_count":36,"outputs":[]}]}